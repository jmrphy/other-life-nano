---
title: "The Technological Republic: A Review"
description: "A critical examination of Alexander Karp's book on technology, power, and the future of the West"
date: "2025-08-20"
draft: true
---

**Reviewed:** *The Technological Republic: Hard Power, Soft Belief, and the Future of the West* by Alexander C. Karp and Nicholas W. Zamiska.

I have to lead with the fact that I was personally a little disappointed. Perhaps I had overly high hopes for this book; I thought it could have been something more. Alexander Karp, the founder of Palantir, is an intellectually provocative figure, a man who studied under Jürgen Habermas and whose unique manner of speaking suggests a mind working on a different plane from his Silicon Valley peers. With a title like *The Technological Republic*, alluding to Plato, and a subtitle promising a treatise on hard power and the future of the West, the variables combined to suggest a profound moment in the intellectual life of the tech world. In retrospect, I don't know what exactly I was expecting—a very original academic monograph on philosophy, technology, and politics? I was somewhat foolish to expect that. It turns out that's not what the book is, but that's okay. It is, instead, a very interesting and competent bestselling nonfiction book, the kind one might find in an airport, and I don't say that with disrespect. For the airport book it is, it's actually quite good, comparatively. We should assess it on its own terms.

To rehearse the main argument, the book is a little messy. It is a collection of observations, critiques of contemporary American culture, and exhortations for business leaders to have more ideas, be bold, and take an interest in national ideals instead of only making consumer apps for profit. It is also, fairly enough, an intellectual backdrop for the Palantir project. The strongest version of its argument calls for a closer relationship between business and government, stating plainly that "It will, however, be a union of the state and the software industry… that will be required for the United States and its allies… to remain as dominant in this century as they were in the last." A "union of the state and the software industry" is a provocative phrase. If you want a merger between business and government, you want fascism. One could call that fascism if taken literally—a chilling but existentially serious dilemma: maybe to win the AI race against China, America needs a soft version of authoritarian state-business fusion. But Karp doesn't say that directly. He flirts with it and then backs off. The book is filled with exhortations to think boldly but not a lot of thinking boldly itself. It laments how business leaders don't speak forthrightly enough, yet it shies away from the deeper, more dangerous arguments its own premises invite.

If you stress-test some of the book's arguments, they don't hold up well. One large hole is its call for a closer relationship between intellectuals, scientists, engineers, and government, reminiscent of Franklin D. Roosevelt's brain trust. The book frames the problem as if no business leaders think boldly and no serious collaboration exists, but that's not exactly true. Since FDR, we've had close collaboration between intellectuals and government, and it hasn't always been good. There is no engagement with the fact that we do see influential leaders shaping government, often not for the better. The book idealizes the era of engineers working with government to build the atomic bomb but fails to grapple with its record: World War I, World War II, Vietnam—massive missteps and senseless violence. It's not crazy that US engineers today might hesitate. The book is more polemic and personal testimony than a serious reckoning with this history.

The book is filled with other extraordinary contradictions. Karp criticizes "food delivery apps" and "online marketing" as a brain drain, but all that consumer stuff also gave us the cloud architectures that enabled the large-scale AI training he champions. The consumer space is deeply interconnected with the foundational technology he wants to harness for national projects. He also claims that tech leaders have "no beliefs," that they are "technological agnostics" whose capacity for "forming their own authentic beliefs… has been severely diminished." But if that is true, do you really want these morally ambivalent people building software for the government? That is not an obviously desirable outcome. Karp's belief in America and the West over China is admirable, but it's not a full argument for everyone to go make government weapons, especially when it never engages with the vast political science literature suggesting that global trade—the very engine of the consumerism he disdains—lowers the chance of major conflict.

But the most fascinating part of this story lies elsewhere, in a place the book does not go: Karp's own intellectual biography. His doctoral dissertation, written in Germany, is a reinterpretation of Theodor Adorno's critique of the "jargon of authenticity." For Adorno, and for the young Karp, talk of authenticity and being—ontology—especially of the Heideggerian variety, degenerates into an in-group slang, an ideological contraption used to exert aggression and exclude outsiders. In his dissertation, Karp argues that ontology is a hollow signifier that serves unstated, violent goals; it pretends that issues are objective and existential when they are in fact socially constructed. The case study is a speech by the writer Martin Walser, who criticized Germany's Holocaust remembrance as a "moral cudgel." Karp analyzes this as a jargon of authenticity used to cast out moral intellectuals and Jews, offering psychological relief to its audience through an act of veiled aggression. The dissertation, in other words, is firmly within what Karp himself would now pejoratively call the "woke" academic current.

There are two very strange things about the relationship between Karp's dissertation and his contemporary work. The first is this reversal from a "woke" critique of power. The second, and more startling, is that one of the key features of the Palantir software is called its *ontology*. The explicit conceptual connection is too stark to overlook. In the dissertation, ontology is ideological aggression that pretends to be high-minded but is really brute force. Palantir, then, appears to be the application of ontology to explicit brute force. It is hard to resist the view that the Palantir CEO is a kind of dark-sided version of the dissertation writer. What he seems to be saying now is that human beings, whether we like it or not, live and thrive through shared aggression towards outsiders. Our only choice is whether we do that unconsciously and dishonestly, or embrace aggression explicitly and use the language of authenticity honestly, as the weapon it really is.

To be sure, Karp's use of "ontology" to describe his data system is a strategic marketing choice, but it is also, genuinely, a question of ontology. As he has said in an interview, "The ontology allows you to take an LLM, use it, refine it, and impose it on your enterprise." The value of AI is only as good as the creative definition of the system in which you deploy it. This requires an accurate theory of what is real and what matters. Define it intelligently, and AI will help you move faster; define it badly, and AI will help you run faster off a cliff. It is an interesting situation where a philosophical insight seems to be generating tremendous enterprise value. And yet, it is also a propagandistic piece of jargon that Karp deploys more effectively than other entrepreneurs, thereby garnering vastly outsized valuation.

It is incredible that this is all sitting there, right in front of us. The man's chief discovery as a graduate student was a critique of how German antisemites used language as a veiled act of aggression. And he literally went and did that exact thing, with the same rare verbiage, but applied it from the perspective of America towards China. I think he would probably admit this. He would say yes, because the West is a more ethical civilizational model, and every society needs an out-group to hold it together. You should just do it honestly and courageously, for the highest good of the best possible in-group. It would be amazing if he said all of this in the book.

This brings us to the book's central, unexamined puzzle: the weird and not fully worked out mind of Alex Karp. He identifies as a left-wing individual, a social democrat who endorsed Kamala Harris. Yet the arguments in his book would seem to find a more natural home with Donald Trump—a businessman, an American nationalist, less concerned with moralistic claptrap. When Elon Musk and David Sacks were moving into Washington, D.C., where was Alex Karp? Why was he not on stage with them, working to install Palantir at the Social Security Administration? I have seen Sam Altman, Larry Ellison, and Jensen Huang on stage at the White House. I have never seen Alex Karp. It's hard to resist the inference that Karp speaks a big game but is somehow either fundamentally confused or fundamentally lacking courage in his own political and philosophical life.

I can't help but float the following thesis: Karp seems to have been waylaid by a kind of West Coast Straussianism. He cites Leo Strauss favorably as a diagnostician of the modern split between facts and values, implicitly warranting his own moralistic agenda. He seems to believe he is entitled to strategic discretion in his self-expression, playing a kind of four-dimensional chess with a coherent esoteric doctrine hidden behind exoteric misdirection. But it seems to me that Straussianism is being totally melted down by technological acceleration. If you try to maintain that kind of balance, the world moves too fast; you end up making no sense, seeming contradictory and anachronistic. The only way to explain the weird attributes of this book and his intellectual biography is to see him as someone whose own moral life has been scrambled by his own instrumental rationality.

Which brings us full circle, because the person who knew this better than anyone else was Adorno. For Adorno, the iron cage of instrumental rationality is so dark and all-pervasive that as soon as you try to achieve anything economically or politically, you are forced to exploit and lie. His only solution was to be a philosopher, to just criticize everything, frankly and honestly. It would be pessimistic and miserable, and it would not have a big market, but it was the only way of living and speaking honestly. I think the best way to ultimately understand Alex Karp is that he's a disciple of Adorno who decided that he could go build a big business while also somehow remaining faithful to his social democratic commitments. If you try to do that, you're just going to get yourself twisted up into knots. You spin wildly around different conceptual points in a way that you justify as pragmatism, but which is ultimately never grounded.

Perhaps what I find so vexing about Karp is that he presents himself as a firebrand. He has a kind of erratic, high-energy, uncalculating enthusiasm in his speech, which is one reason I expected more from this book. But when it comes down to putting words on paper, it seems his gracious bluntness does not go very deep. The real lesson here may be that this kind of secular Straussian civic responsibility just doesn't work in a technologically accelerating civilization. The only cognitive management approach that can ride the waves of technology and culture today is a kind of reckless frankness. As much as I admire Alex Karp—I really wanted this to be a badass book—he seems demonstrably tied up by his own inconsistencies. It reveals the inadequacy of his philosophical premises, which we are only in a position to trace because, to his credit, he has at least produced those traces. What we can certainly see is a fascinating life and trajectory. He is still relatively young, and I would not be surprised if he still evolves a lot. Not to mention, it is genuinely difficult to write an intellectually serious book when you're the leader of a billion-dollar enterprise. So, you know, respect that as well.